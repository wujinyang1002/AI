import io
import time
from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI



def get_ai_response(memory, user_prompt, system_prompt):
    try:
        model = ChatOpenAI(
            api_key=st.session_state['API_KEY'],
            model=st.session_state.selected_model,
            base_url='https://twapi.openai-hk.com/v1',
            temperature=st.session_state.model_temperature,
            max_tokens=st.session_state.model_max_length
        )
        chain = ConversationChain(llm=model, memory=memory)
        full_prompt = f"{system_prompt}\n{user_prompt}"
        return chain.invoke({'input': full_prompt})['response']
    except Exception as err:
        return 'æ— æ³•è·å–æœåŠ¡å™¨å“åº”.....'


def extract_chart_type(ai_response):
    chart_keywords = {
        "æŠ˜çº¿å›¾": ["line", "è¶‹åŠ¿", "å˜åŒ–"],
        "æŸ±çŠ¶å›¾": ["bar", "æ¯”è¾ƒ", "åˆ†å¸ƒ"],
        "é¥¼å›¾": ["pie", "æ¯”ä¾‹", "å æ¯”"],
        "æ•£ç‚¹å›¾": ["scatter", "å…³ç³»", "ç›¸å…³æ€§"]
    }
    for chart, keywords in chart_keywords.items():
        for keyword in keywords:
            if keyword in ai_response.lower():
                return chart
    return "æŠ˜çº¿å›¾"


def generate_chart(df, chart_type):
    plt.style.use('ggplot')
    fig, ax = plt.subplots(figsize=(10, 6))
    fig.patch.set_facecolor('#F8F9FF')
    ax.set_facecolor('#F8F9FF')
    colors = ['#2A27C7', '#6C63FF', '#00B4D8']

    try:
        if "æŠ˜çº¿å›¾" in chart_type:
            ax.plot(df.iloc[:, 0], df.iloc[:, 1], color=colors[0], marker='o')
        elif "æŸ±çŠ¶å›¾" in chart_type:
            ax.bar(df.iloc[:, 0], df.iloc[:, 1], color=colors)
        elif "é¥¼å›¾" in chart_type:
            ax.pie(df.iloc[:, 1], labels=df.iloc[:, 0], autopct='%1.1f%%', colors=colors)
        elif "æ•£ç‚¹å›¾" in chart_type:
            ax.scatter(df.iloc[:, 0], df.iloc[:, 1], color=colors[0])
        else:
            st.error(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹ï¼š{chart_type}")
            return

        ax.set_title(chart_type, fontsize=14, color='#2A27C7')
        if chart_type != "é¥¼å›¾":
            ax.set_xlabel(df.columns[0])
            ax.set_ylabel(df.columns[1])
        ax.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        st.download_button(
            label="ä¸‹è½½å›¾è¡¨",
            data=buf.getvalue(),
            file_name=f"superai_chart_{datetime.now().strftime('%Y%m%d%H%M')}.png",
            mime="image/png"
        )
    except Exception as e:
        st.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
    finally:
        plt.close()


header_container = st.container()
with header_container:
    cols = st.columns([1, 8, 1])
    with cols[1]:
        st.markdown("""
            <div style="text-align:center; margin-bottom:40px">
                <h1 style="margin-bottom:0">SuperAI æ™ºèƒ½åˆ†æåŠ©æ‰‹ğŸš€</h1>
                <p style="color:#6C63FF; font-size:1.2rem">æ•°æ®æ´å¯Ÿä»æœªå¦‚æ­¤ç®€å•</p>
            </div>
        """, unsafe_allow_html=True)

if 'messages' not in st.session_state:
    st.session_state.messages = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
    st.session_state.memory = ConversationBufferMemory(return_messages=True)
    st.session_state.history = []
    st.session_state.df = None
    st.session_state.txt_content = None
    st.session_state.viewing_history = False
    st.session_state.current_chat_index = 0

with st.sidebar:
    st.title("è¶…çº§æ™ºèƒ½åˆ†æåŠ©æ‰‹")
    api_key=st.text_input('è¯·è¾“å…¥ä½ çš„Key', type='password')
    st.session_state['API_KEY']=api_key
    if st.button("æ–°å»ºä¼šè¯"):
        st.session_state.messages = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
        st.session_state.memory = ConversationBufferMemory(return_messages=True)
        st.session_state.viewing_history = False

    st.subheader("å†å²ä¼šè¯")
    if len(st.session_state.messages) > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ¶ˆæ¯æ¥æ˜¾ç¤ºä¼šè¯
        for i in range(1, len(st.session_state.messages), 2):
            if i + 1 < len(st.session_state.messages):
                user_msg = st.session_state.messages[i]
                ai_msg = st.session_state.messages[i + 1]
                st.caption(f"ç”¨æˆ·: {user_msg['content'][:30]}...")
                st.caption(f"AI: {ai_msg['content'][:30]}...")
                if st.button(f"æŸ¥çœ‹ä¼šè¯ {i // 2 + 1}", key=f"view_{i // 2}"):
                    st.session_state.viewing_history = True
                    st.session_state.current_chat_index = i
                if st.button(f"åˆ é™¤ä¼šè¯ {i // 2 + 1}", key=f"delete_{i // 2}"):
                    # ç¡®ä¿ä¸ä¼šåˆ é™¤æœ€åä¸€ä¸ªAIæ¶ˆæ¯
                    if i + 1 < len(st.session_state.messages):
                        del st.session_state.messages[i:i+2]
    st.markdown("<hr/>", unsafe_allow_html=True)

    st.subheader("æ¨¡å‹é…ç½®")
    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©AIæ¨¡å‹",
        ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo", "gpt-4"],
        index=0,
        help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )

    st.session_state.model_temperature = st.slider("æ¸©åº¦ (Temperature)", 0.0, 1.0, 0.7, 0.1)
    st.session_state.model_max_length = st.slider("æœ€å¤§é•¿åº¦", 100, 2000, 1000)
    system_prompt = st.text_area("ç³»ç»Ÿæç¤ºè¯", "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜")

# æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å¼æ˜¾ç¤ºä¸åŒç•Œé¢
if st.session_state.viewing_history:
    st.subheader("å†å²æ¶ˆæ¯")
    current_chat_index = st.session_state.current_chat_index
    if current_chat_index + 1 < len(st.session_state.messages):
        user_msg = st.session_state.messages[current_chat_index]
        ai_msg = st.session_state.messages[current_chat_index + 1]
        st.markdown(f"**ç”¨æˆ·**: {user_msg['content']}")
        st.markdown(f"**AI**: {ai_msg['content']}")
    st.button("è¿”å›å½“å‰å¯¹è¯", on_click=lambda: setattr(st.session_state, 'viewing_history', False))
else:
    # ä¸»ç•Œé¢æ–‡ä»¶ä¸Šä¼ 
    st.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    file = st.file_uploader("ä¸Šä¼ CSVã€Excelæˆ–TXTæ–‡ä»¶", type=["csv", "xlsx", "txt"], key="file_uploader")
    if file:
        try:
            file_type = file.name.split('.')[-1]
            if file_type in ['csv', 'xlsx']:
                df = pd.read_csv(file) if file_type == 'csv' else pd.read_excel(file)
                st.session_state.df = df
                with st.expander("æŸ¥çœ‹æ•°æ®é¢„è§ˆ"):
                    st.dataframe(df.head(8), use_container_width=True, height=300)
                    st.caption(f"æ•°æ®ç»´åº¦ï¼š{df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            elif file_type == 'txt':
                txt_content = file.read().decode('utf-8')
                st.session_state.txt_content = txt_content
                with st.expander("æŸ¥çœ‹TXTæ–‡ä»¶å†…å®¹"):
                    st.text_area("", txt_content, height=300)
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")

    for message in st.session_state.messages:
        role = "user" if message["role"] == "human" else "assistant"
        with st.chat_message(role):
            st.write(message["content"])

    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", key="user_input"):
        if not api_key:
            st.info('è¯·è¾“å…¥ä½ çš„ä¸“å±å¯†é’¥')
            st.stop()
        st.session_state.messages.append({'role': 'human', 'content': prompt})
        with st.spinner('AI æ­£åœ¨æ€è€ƒï¼Œè¯·ç¨ç­‰...'):
            progress_bar = st.progress(0)
            response_container = st.empty()
            full_response = ""

            analysis_request = f"åˆ†æè¯·æ±‚ï¼š{prompt}\n"
            if st.session_state.df is not None:
                analysis_request += f"æ•°æ®ç»“æ„ï¼š{st.session_state.df.columns.tolist()}\n"
                analysis_request += f"æ•°æ®ç»´åº¦ï¼š{st.session_state.df.shape}\n"

                if st.session_state.df.size < 10000:
                    analysis_request += f"å®Œæ•´æ•°æ®ï¼š{st.session_state.df.to_csv(index=False)}\n"
                else:
                    analysis_request += "æ•°æ®è¾ƒå¤§ï¼ŒæœªåŒ…å«å®Œæ•´æ•°æ®ã€‚\n"
            elif st.session_state.txt_content:
                analysis_request += f"æ–‡æœ¬å†…å®¹ï¼š{st.session_state.txt_content[:1000]}..."

            ai_response = get_ai_response(st.session_state.memory, analysis_request, system_prompt)

            for i in range(len(ai_response)):
                full_response = ai_response[:i + 1]
                response_container.write(full_response)
                progress_bar.progress((i + 1) / len(ai_response))
                time.sleep(0.03)

            st.session_state.messages.append({'role': 'ai', 'content': full_response})
            st.session_state.memory.save_context({'input': prompt}, {'output': full_response})

            if st.session_state.df is not None:
                if "å•ä½åç§°" in st.session_state.df.columns:
                    unit_counts = st.session_state.df["å•ä½åç§°"].value_counts()
                    st.write("### å•ä½åç§°å‡ºç°æ¬¡æ•°åˆ†æ")
                    st.write(unit_counts)
                    st.bar_chart(unit_counts)

            if any(keyword in full_response for keyword in ["å›¾è¡¨", "å›¾å½¢", "å¯è§†åŒ–"]):
                chart_type = extract_chart_type(full_response)
                generate_chart(st.session_state.df, chart_type)